{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPZ3joa2+cJun+E+JZlCzQP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/magikarp01/SIFNetflix/blob/master/SIF_Netflix_Dataset_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A notebook with code for predicting the quality of a movie or series. The notebook uses multiple regression techniques and neural networks in order to handle different kinds of predictive input.\n",
        "\n"
      ],
      "metadata": {
        "id": "x4WjUEjCooQQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-SW5MmkuoWBW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import math\n",
        "import scipy\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn import preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read dataset into dataframe\n",
        "df = pd.read_excel(\"Netflix Dataset Latest 2021.xlsx\")"
      ],
      "metadata": {
        "id": "A50SlbX8pfwV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stratify data by movie or series, since they are judged very differently\n",
        "movie_dataframe = df[df[\"Series or Movie\"] == \"Movie\"].reset_index()\n",
        "series_dataframe = df[df[\"Series or Movie\"] == \"Series\"].reset_index()"
      ],
      "metadata": {
        "id": "7safIHyLrsXM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, a multiple regression between the genres a movie/series is part of and the IMDb score"
      ],
      "metadata": {
        "id": "r36_5fSdtEdp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# functional because want to be able to work with either movie_dataframe or series_dataframe\n",
        "# returns x_data, y_data\n",
        "# x_data is 2d np array of whether each movie/series has a particular genre\n",
        "# y_data is 1d np array of imdb reviews\n",
        "def preprocess_genre_regression(dataframe):\n",
        "  genre_column = dataframe[\"Genre\"]\n",
        "  imdb_column = dataframe[\"IMDb Score\"]\n",
        "  # a list of the (string) genres\n",
        "  genre_list = []\n",
        "\n",
        "  # a list of imdb reviews for each entry\n",
        "  imdb_reviews = []\n",
        "\n",
        "  # a list of the genres for each entry\n",
        "  genre_data = []\n",
        "  \n",
        "  # process data to handle empty/bad rows\n",
        "  for i in range(len(genre_column)):\n",
        "    genre_cell = genre_column[i]\n",
        "    if genre_cell is not None and imdb_column[i] is not None and not math.isnan(imdb_column[i]):\n",
        "        try:\n",
        "            cell_genres = genre_cell.split(\", \")\n",
        "            genre_data.append(cell_genres)\n",
        "            imdb_reviews.append(imdb_column[i])\n",
        "        except AttributeError:\n",
        "            continue\n",
        "\n",
        "        for genre in cell_genres:\n",
        "            if genre not in genre_list:\n",
        "                genre_list.append(genre)\n",
        "\n",
        "  print(genre_list)\n",
        "  genredict = {k: v for v, k in enumerate(genre_list)}\n",
        "\n",
        "  # x_data is a 2d array, each row is an array of binary entries\n",
        "  # each binary entry corresponds to if movie/series is part of a genre \n",
        "  # 0 if no and 1 if yes\n",
        "  x_data = []\n",
        "  for entry in genre_data:\n",
        "      entry_genres = [0]*len(genre_list)\n",
        "      for genre in entry:\n",
        "          entry_genres[genredict[genre]] = 1\n",
        "      x_data.append(entry_genres)\n",
        "  x_data = np.array(x_data)\n",
        "  y_data = np.array(imdb_reviews)/10\n",
        "\n",
        "  return x_data, y_data, genre_list\n"
      ],
      "metadata": {
        "id": "Clu_zcZwsqJW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform the multiple regression on the processed data from previous function\n",
        "def train_genre_regression(x_data, y_data, test_size=0.2, random_state=101, print_output = False):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(\n",
        "    x_data, y_data, test_size=test_size, random_state=random_state)\n",
        "\n",
        "  # creating a regression model\n",
        "  model = LinearRegression()\n",
        "\n",
        "  # fitting the model\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  # making predictions\n",
        "  predictions = model.predict(X_test)\n",
        "\n",
        "  # model evaluation\n",
        "  print('mean_squared_error : ', mean_squared_error(y_test, predictions))\n",
        "  # print('mean_absolute_error : ', mean_absolute_error(y_test, predictions))\n",
        "  print(f'model R^2: {model.score(X_test, y_test)}')\n",
        "  # print(f'model coefficients: {model.coef_}')\n",
        "\n",
        "  if print_output:\n",
        "      for i in range(len(y_test)):\n",
        "        print(f\"predicts {predictions[i]}, actual review is {y_test[i]}\")\n",
        "\n",
        "  return model\n",
        "\n",
        "def model_output(model, genre_list):\n",
        "  print(model.summary) \n",
        "  coef_dic = dict(zip(genre_list, model.coef_))\n",
        "  for k, v in coef_dic.items():\n",
        "      print(f\"For genre {k}, the coefficient is {v}\") "
      ],
      "metadata": {
        "id": "EA1oGB2lv8ox"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# put it all together\n",
        "def genre_regression(dataframe):\n",
        "  x_data, y_data, genre_list = preprocess_genre_regression(dataframe)\n",
        "  model = train_genre_regression(x_data, y_data)\n",
        "  model_output(model, genre_list)\n",
        "  return model\n",
        "\n",
        "genre_regression(movie_dataframe)\n",
        "# genre_regression(series_dataframe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJF7xXlJwf8m",
        "outputId": "61200de2-43f8-4a5a-c964-a9584cfbc521"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Comedy', 'Romance', 'Drama', 'Crime', 'Fantasy', 'Mystery', 'Thriller', 'Short', 'Action', 'Adventure', 'Sci-Fi', 'Music', 'Family', 'Biography', 'Animation', 'War', 'History', 'Documentary', 'Horror', 'Film-Noir', 'Sport', 'Western', 'Musical', 'Reality-TV', 'Adult', 'News', 'Talk-Show']\n",
            "mean_squared_error :  0.006606608489484805\n",
            "model R^2: 0.16982544975353442\n",
            "For genre Comedy, the coefficient is -0.01602164088416835\n",
            "For genre Romance, the coefficient is -0.012631617961811675\n",
            "For genre Drama, the coefficient is 0.02420954061188718\n",
            "For genre Crime, the coefficient is 0.009489141835484157\n",
            "For genre Fantasy, the coefficient is -0.0009438763731072829\n",
            "For genre Mystery, the coefficient is 0.003640220577919371\n",
            "For genre Thriller, the coefficient is -0.02632799540434819\n",
            "For genre Short, the coefficient is 0.03233820605460993\n",
            "For genre Action, the coefficient is -0.0168781347073299\n",
            "For genre Adventure, the coefficient is -0.005170742785502887\n",
            "For genre Sci-Fi, the coefficient is -0.004478045178016285\n",
            "For genre Music, the coefficient is -0.0016972659305075255\n",
            "For genre Family, the coefficient is -0.0403017058918589\n",
            "For genre Biography, the coefficient is 0.005034468589700726\n",
            "For genre Animation, the coefficient is 0.061885380612337226\n",
            "For genre War, the coefficient is 0.017050789309623778\n",
            "For genre History, the coefficient is 0.0006448594400463618\n",
            "For genre Documentary, the coefficient is 0.051214848208316996\n",
            "For genre Horror, the coefficient is -0.053653312149320224\n",
            "For genre Film-Noir, the coefficient is -0.01566806423306612\n",
            "For genre Sport, the coefficient is -0.007013205859832348\n",
            "For genre Western, the coefficient is 0.018468744498374007\n",
            "For genre Musical, the coefficient is 0.00480803522144968\n",
            "For genre Reality-TV, the coefficient is 0.03670262280995738\n",
            "For genre Adult, the coefficient is 0.07433424077176892\n",
            "For genre News, the coefficient is 0.021186356298026846\n",
            "For genre Talk-Show, the coefficient is 0.04678157338795724\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another model, determining whether runtime has an affect on the quality of the movie"
      ],
      "metadata": {
        "id": "yPCmu4I341Ia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def runtime_stratification(dataframe):\n",
        "  runtime_column = dataframe[\"Runtime\"]\n",
        "  imdb_column = dataframe[\"IMDb Score\"]\n",
        "  \n",
        "  # runtime_data is list of 4 arrays, each array has all imdb reviews for one runtime\n",
        "  # 0 corresponding to <30 mins, 1 for 30-60 mins, 2 for 1-2 hour, 3 for > 2 hrs\n",
        "\n",
        "  runtime_data = [[], [], [], []]\n",
        "  # possible values in the runtime cell\n",
        "  possible_runtimes = {\"< 30 minutes\": 0, \"30-60 mins\": 1, \"1-2 hour\": 2, \"> 2 hrs\": 3}\n",
        "  # process data to handle empty/bad rows\n",
        "  for i in range(len(runtime_column)):\n",
        "    runtime_cell = runtime_column[i]\n",
        "    if not pd.isnull(runtime_cell) and not pd.isnull(imdb_column[i]):\n",
        "    # and runtime_cell is not None and imdb_column[i] is not None \\\n",
        "    # and not math.isnan(imdb_column[i]) and str(runtime_cell) != 'nan':\n",
        "    # if runtime_cell is not None \\\n",
        "    #  and imdb_column[i] is not None and not math.isnan(imdb_column[i]):\n",
        "# and not math.isnan(runtime_cell)\n",
        "        try:\n",
        "            runtime_data[possible_runtimes[runtime_cell]].append(imdb_column[i])\n",
        "        except AttributeError:\n",
        "            continue\n",
        "\n",
        "  runtime_names = list(possible_runtimes.keys())\n",
        "  for i in range(4):\n",
        "    runtime_data[i] = [x for x in runtime_data[i] if np.isnan(x) == False]\n",
        "\n",
        "  for i in range(4):\n",
        "    if len(runtime_data[i]) == 0:\n",
        "      print(f\"No entries have runtime {runtime_names[i]}\")\n",
        "    else:\n",
        "      print(f\"For runtime {runtime_names[i]}, average IMDb score is {np.average(runtime_data[i])}, \" +\n",
        "            f\"variance in IMDb score is {np.var(runtime_data[i])}\")\n",
        "\n",
        "  return runtime_data\n"
      ],
      "metadata": {
        "id": "KWqVZH7A40Ll"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Movies:\")\n",
        "movie_runtimes = runtime_stratification(movie_dataframe)\n",
        "print()\n",
        "print(\"Series:\")\n",
        "nan_runtime = runtime_stratification(series_dataframe)\n",
        "\n",
        "for i in nan_runtime:\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okZA7r0KGgio",
        "outputId": "2011dabb-0bb6-4bbb-802e-6f812cd9eef7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Movies:\n",
            "For runtime < 30 minutes, average IMDb score is 7.076344086021504, variance in IMDb score is 0.46417158052954105\n",
            "For runtime 30-60 mins, average IMDb score is 7.133088235294117, variance in IMDb score is 0.3467728157439447\n",
            "For runtime 1-2 hour, average IMDb score is 6.632261768082665, variance in IMDb score is 0.7887142491200274\n",
            "For runtime > 2 hrs, average IMDb score is 7.1072398190045245, variance in IMDb score is 0.5618221810130247\n",
            "\n",
            "Series:\n",
            "For runtime < 30 minutes, average IMDb score is 7.543082021541011, variance in IMDb score is 0.4634711970835687\n",
            "No entries have runtime 30-60 mins\n",
            "No entries have runtime 1-2 hour\n",
            "No entries have runtime > 2 hrs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's find out how significant these results are. We can run t-tests on the different runtimes for movies (not on series, there are no different runtimes here)"
      ],
      "metadata": {
        "id": "DVZ7aKXLLlip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4 t-tests, seeing if each runtime's imdb reviews are significantly different\n",
        "# from the all runtime imdb reviews\n",
        "\n",
        "all_reviews = movie_runtimes[0] + movie_runtimes[1] + movie_runtimes[2] + movie_runtimes[3]\n",
        "ttests = [scipy.stats.ttest_ind(all_reviews, movie_runtimes[i]) for i in range(4)]\n"
      ],
      "metadata": {
        "id": "sqWwwDesLk_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time for something more complex. You know when you read a summary for a show/movie, and you know that it's just gonna be terrible? We could try to predict the IMDb score from the summary alone, using NLP techniques and a neural network."
      ],
      "metadata": {
        "id": "Y47xRYIsABs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# encode summary into a 512-dimensional vector, that preserves semantics and meaning\n",
        "# save in np array\n",
        "def preprocess_summary_prediction(dataframe, hub_layer):\n",
        "  summary_column = dataframe[\"Summary\"]\n",
        "  imdb_column = dataframe[\"IMDb Score\"]\n",
        "\n",
        "  # a list of imdb reviews for each entry\n",
        "  imdb_reviews = []\n",
        "\n",
        "  # a 2d numpy array of the encoded summaries\n",
        "  summary_data = []\n",
        "  \n",
        "  # process data to handle empty/bad rows\n",
        "  for i in range(len(summary_column)):\n",
        "    # print(i)\n",
        "    summary_cell = summary_column[i]\n",
        "    if not pd.isnull(summary_cell) and not pd.isnull(imdb_column[i]):\n",
        "        try:\n",
        "            # encoded_summary = hub_layer([summary_cell])\n",
        "            # summary_data.append(encoded_summary)\n",
        "            summary_data.append([summary_cell])\n",
        "            imdb_reviews.append(imdb_column[i])\n",
        "        except AttributeError:\n",
        "            continue\n",
        "\n",
        "  summary_data = np.array(summary_data)\n",
        "  imdb_reviews = np.array(imdb_reviews)/10\n",
        "  return summary_data, imdb_reviews"
      ],
      "metadata": {
        "id": "Fr9z4uGgDmvb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess data\n",
        "\n",
        "embedding = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
        "hub_layer = hub.KerasLayer(embedding, input_shape=[], \n",
        "                           dtype=tf.string, trainable=True)\n",
        "summary_data, imdb_reviews = preprocess_summary_prediction(movie_dataframe, hub_layer)"
      ],
      "metadata": {
        "id": "3Kq5sVmTD7fy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(summary_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEbNXHlYEEYx",
        "outputId": "ae81ca6d-a3bb-46c9-ea20-e87fa3252e62"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6998, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "# model.add()\n",
        "model.add(hub_layer)\n",
        "model.add(tf.keras.layers.Dense(16, activation='sigmoid'))\n",
        "model.add(tf.keras.layers.Dense(1, activation='relu'))\n",
        "model.summary()\n",
        "config = model.get_config() # Returns pretty much every information about your model\n",
        "print(config[\"layers\"][0][\"config\"][\"batch_input_shape\"]) # returns a tuple of width, height and channels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JECl1f2FEQl_",
        "outputId": "b5faa0fe-58c4-44ec-b18a-4ffbfe3603ce"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer (KerasLayer)    (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                8208      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,806,049\n",
            "Trainable params: 256,806,049\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "(None,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.MeanSquaredError(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "VB2S9vCrGOn6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(imdb_reviews)\n",
        "print(summary_data)\n",
        "print(summary_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJBJuDddG52K",
        "outputId": "b404ec03-1779-4bd2-9027-f4c32882e0b4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.58 0.74 0.67 ... 0.62 0.73 0.78]\n",
            "[['When nerdy Johanna moves to London, things get out of hand when she reinvents herself as a bad-mouthed music critic to save her poverty-stricken family.']\n",
            " ['After her ex-boyfriend cons her out of a large sum of money, a former bank employee tricks a scam artist into helping her swindle him in retaliation.']\n",
            " ['An unhappily married farm worker struggling to care for her children reflects on her lost youth and the scandalous moment that cost her true love.']\n",
            " ...\n",
            " ['Computer users across the globe log onto the virtual world of Second Life. But some users lives are dramatically consumed by this alternate reality.']\n",
            " ['In an idyllic port town on Australias west coast in the summer of 1969, carefree 16-year-old Willie enjoys hanging out with his pals and wooing a beautiful singer named Rosie -- until his mom ships him back to a Catholic boarding school in Perth.']\n",
            " ['In his third show, DaniÃ«l Arends argues that good deeds are a form of self interest, and evil deeds are a hobby.']]\n",
            "(6998, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    summary_data, imdb_reviews, test_size=.2, random_state=101)\n",
        "# print(X_train.shape)\n",
        "# print(X_test.shape)\n",
        "\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(\n",
        "    X_train, y_train, test_size=.2, random_state=101)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_validation.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "y_train = np.array(y_train).astype('float32')\n",
        "y_test = np.array(y_test).astype('float32')\n",
        "y_validation = np.array(y_validation).astype('float32')\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "print(y_validation.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWyRfN_DErYz",
        "outputId": "838e1729-cde1-4619-9a9c-b5184df0c31c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4478, 1)\n",
            "(1120, 1)\n",
            "(1400, 1)\n",
            "(4478,)\n",
            "(1400,)\n",
            "(1120,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x=X_train, y=y_train,\n",
        "                    epochs=5,\n",
        "                    validation_data=(X_validation, y_validation),\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-zP-4-OI7Nb",
        "outputId": "7de25360-d4e5-4fb5-98fc-79cfeb8449a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "140/140 [==============================] - 447s 3s/step - loss: 0.4640 - accuracy: 0.0000e+00 - val_loss: 0.4624 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/5\n",
            "140/140 [==============================] - 453s 3s/step - loss: 0.4640 - accuracy: 0.0000e+00 - val_loss: 0.4624 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/5\n",
            "140/140 [==============================] - 461s 3s/step - loss: 0.4640 - accuracy: 0.0000e+00 - val_loss: 0.4624 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/5\n",
            " 21/140 [===>..........................] - ETA: 6:05 - loss: 0.4682 - accuracy: 0.0000e+00"
          ]
        }
      ]
    }
  ]
}