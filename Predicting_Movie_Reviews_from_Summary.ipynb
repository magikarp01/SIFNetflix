{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOklMtpCrsIjj7YCDGxYgqL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/magikarp01/SIFNetflix/blob/master/Predicting_Movie_Reviews_from_Summary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "qK2TVNkJeADw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reading from datasheet\n",
        "\n",
        "dataframe1 = pd.read_excel(\"Netflix Dataset Latest 2021.xlsx\")\n",
        "# print(dataframe1)\n",
        "tags = dataframe1[\"Tags\"]\n",
        "imdb_scores_init = dataframe1[\"IMDb Score\"]\n",
        "summaries_init = dataframe1[\"Summary\"]\n",
        "# print(imdb_scores)\n",
        "\n",
        "summaries_clean = []\n",
        "imdb_scores_clean = []\n",
        "\n",
        "# remove the blank elements\n",
        "for i in range(len(summaries_init)):\n",
        "  if summaries_init[i] == None or imdb_scores_init[i] == None:\n",
        "    continue\n",
        "  elif math.isnan(imdb_scores_init[i]):\n",
        "    print(\"nan\")\n",
        "    continue\n",
        "  else:\n",
        "    summaries_clean.append(summaries_init[i])\n",
        "    imdb_scores_clean.append(imdb_scores_init[i])"
      ],
      "metadata": {
        "id": "EgwiRy4cex1J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db07b4e5-ec5d-4f78-9d44-2790de935cb4"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding the text of summaries\n",
        "\n",
        "embedding = \"https://tfhub.dev/google/nnlm-en-dim50/2\"\n",
        "hub_layer = hub.KerasLayer(embedding, input_shape=[], \n",
        "                           dtype=tf.string, trainable=True)"
      ],
      "metadata": {
        "id": "Lhw7oipqeXQq"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# format input, output into tensors\n",
        "summaries = np.array(summaries_clean)\n",
        "imdb_scores = np.array(imdb_scores_clean)/10\n",
        "# [summary for summary in summaries])\n",
        "print(summaries.shape)\n",
        "print(imdb_scores.shape)\n",
        "print(summaries)\n",
        "print(imdb_scores)\n",
        "# print(np.max(imdb_scores))\n",
        "print(hub_layer([summaries[3]]))\n",
        "\n",
        "\n",
        "# for i in range(9425):\n",
        "#   print(summaries[i])\n",
        "#   print(f\"encoding {i}: {hub_layer([summaries[i]])}\")\n",
        "  \n",
        "encoded_summaries = np.array([hub_layer([summary]) for summary in summaries])\n",
        "print(encoded_summaries)\n",
        "print(encoded_summaries.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRGbEVkGfLyg",
        "outputId": "43091a41-08a7-4a19-a198-30875fd5da0c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9417,)\n",
            "(9417,)\n",
            "['A med student with a supernatural gift tries to cash in on his abilities by facing off against ghosts, till a wandering spirit brings romance instead.'\n",
            " 'When nerdy Johanna moves to London, things get out of hand when she reinvents herself as a bad-mouthed music critic to save her poverty-stricken family.'\n",
            " 'After her ex-boyfriend cons her out of a large sum of money, a former bank employee tricks a scam artist into helping her swindle him in retaliation.'\n",
            " ...\n",
            " 'In an idyllic port town on Australias west coast in the summer of 1969, carefree 16-year-old Willie enjoys hanging out with his pals and wooing a beautiful singer named Rosie -- until his mom ships him back to a Catholic boarding school in Perth.'\n",
            " 'In his third show, DaniÃ«l Arends argues that good deeds are a form of self interest, and evil deeds are a hobby.'\n",
            " 'Madagascar goes wild with holiday spirit in this set of Valentines Day and Christmas-themed tales featuring everyones favorite animal characters.']\n",
            "[0.79 0.58 0.74 ... 0.73 0.78 0.68]\n",
            "tf.Tensor(\n",
            "[[ 0.15603384 -0.04827688 -0.01749985 -0.1438108  -0.16196081  0.17907974\n",
            "  -0.02771539 -0.20814517 -0.03515712 -0.12613301 -0.16637544  0.083993\n",
            "  -0.26764655 -0.01131292 -0.01781165 -0.19981927  0.00814829 -0.03029742\n",
            "  -0.00836706  0.06747427  0.05352956 -0.03308471 -0.15473218 -0.51325136\n",
            "   0.02974907  0.32684848 -0.22270525 -0.18662123  0.11735884 -0.26663274\n",
            "   0.2229121  -0.1293875   0.33545935 -0.10798961 -0.33414316 -0.12098016\n",
            "   0.05037718 -0.18595117  0.07038192 -0.22940093  0.14367743  0.06287009\n",
            "  -0.10796936  0.07208358  0.10561199 -0.3152351   0.49718675 -0.04721688\n",
            "   0.03466751  0.3135862 ]], shape=(1, 50), dtype=float32)\n",
            "[[[ 0.26793113 -0.07360907  0.00643026 ...  0.21096282  0.21854025\n",
            "    0.01279267]]\n",
            "\n",
            " [[ 0.304084    0.09700795 -0.28774196 ... -0.08493562 -0.01096375\n",
            "   -0.00492603]]\n",
            "\n",
            " [[ 0.4705423  -0.12867242  0.0610166  ...  0.21631518 -0.04978862\n",
            "   -0.19080544]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 0.2707062  -0.27072558 -0.15034728 ... -0.14354807 -0.24442603\n",
            "   -0.07422142]]\n",
            "\n",
            " [[ 0.3391952   0.00707966  0.2564633  ...  0.09381999 -0.14359516\n",
            "   -0.03217785]]\n",
            "\n",
            " [[ 0.08474249  0.08060661 -0.09958405 ...  0.09197403  0.21898817\n",
            "    0.31129894]]]\n",
            "(9417, 1, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "# model.add()\n",
        "model.add(hub_layer)\n",
        "model.add(tf.keras.layers.Dense(16, activation='sigmoid'))\n",
        "model.add(tf.keras.layers.Dense(1, activation='relu'))\n",
        "model.summary()\n",
        "\n",
        "config = model.get_config() # Returns pretty much every information about your model\n",
        "print(config[\"layers\"][0][\"config\"][\"batch_input_shape\"]) # returns a tuple of width, height and channels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37Cqcqt1gw7C",
        "outputId": "d76d414f-f107-40de-e957-cf28bf0b736e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer_3 (KerasLayer)  (None, 50)                48190600  \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 16)                816       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 48,191,433\n",
            "Trainable params: 48,191,433\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "(None,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.MeanSquaredError(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "P11OFbtiki7Q"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = np.array(list(zip(summaries, imdb_scores)))\n",
        "# all_data = tf.data.Dataset.from_tensor_slices((summaries, imdb_scores))\n",
        "\n",
        "print(all_data.shape)\n",
        "train_data = all_data[:6000, ]\n",
        "validation_data = all_data[6000:, ]\n",
        "print(train_data.shape)\n",
        "print(validation_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iwHvo-ak4JC",
        "outputId": "e1db85aa-2be7-4427-9182-639f3dc66d61"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9417, 2)\n",
            "(6000, 2)\n",
            "(3417, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow_datasets as tfds\n",
        "\n",
        "# # Split the training set into 60% and 40% to end up with 15,000 examples\n",
        "# # for training, 10,000 examples for validation and 25,000 examples for testing.\n",
        "# train_data, validation_data, test_data = tfds.load(\n",
        "#     name=\"imdb_reviews\", \n",
        "#     split=('train[:60%]', 'train[60%:]', 'test'),\n",
        "#     as_supervised=True)\n",
        "\n",
        "# print(train_data)"
      ],
      "metadata": {
        "id": "vf5lxnsoyyPf"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert not np.any(np.isnan(imdb_scores))\n",
        "# assert not np.any(np.isnan(summaries))"
      ],
      "metadata": {
        "id": "2P-itTgCsMRG"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# history = model.fit(train_data.shuffle(6000).batch(512),\n",
        "#                     epochs=10,\n",
        "#                     validation_data=validation_data.batch(512),\n",
        "#                     verbose=1)\n",
        "\n",
        "print(summaries)\n",
        "# summaries = tf.convert_to_tensor(np.asarray(summaries))\n",
        "# imdb_scores = tf.convert_to_tensor(imdb_scores)\n",
        "train_x = summaries[:6000]\n",
        "train_y = imdb_scores[:6000].astype('float32')\n",
        "validation_x = summaries[6000:7000]\n",
        "validation_y = imdb_scores[6000:7000].astype('float32')\n",
        "\n",
        "history = model.fit(x=train_x, y=train_y,\n",
        "                    epochs=10,\n",
        "                    validation_data=(validation_x, validation_y),\n",
        "                    verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IRykIRfrFCq",
        "outputId": "5cde813d-e29d-4b32-9091-e6a768ca7a11"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A med student with a supernatural gift tries to cash in on his abilities by facing off against ghosts, till a wandering spirit brings romance instead.'\n",
            " 'When nerdy Johanna moves to London, things get out of hand when she reinvents herself as a bad-mouthed music critic to save her poverty-stricken family.'\n",
            " 'After her ex-boyfriend cons her out of a large sum of money, a former bank employee tricks a scam artist into helping her swindle him in retaliation.'\n",
            " ...\n",
            " 'In an idyllic port town on Australias west coast in the summer of 1969, carefree 16-year-old Willie enjoys hanging out with his pals and wooing a beautiful singer named Rosie -- until his mom ships him back to a Catholic boarding school in Perth.'\n",
            " 'In his third show, DaniÃ«l Arends argues that good deeds are a form of self interest, and evil deeds are a hobby.'\n",
            " 'Madagascar goes wild with holiday spirit in this set of Valentines Day and Christmas-themed tales featuring everyones favorite animal characters.']\n",
            "Epoch 1/10\n",
            "188/188 [==============================] - 109s 573ms/step - loss: 0.4968 - accuracy: 0.0000e+00 - val_loss: 0.4837 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 105s 559ms/step - loss: 0.4968 - accuracy: 0.0000e+00 - val_loss: 0.4837 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 105s 558ms/step - loss: 0.4968 - accuracy: 0.0000e+00 - val_loss: 0.4837 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 104s 556ms/step - loss: 0.4968 - accuracy: 0.0000e+00 - val_loss: 0.4837 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 105s 557ms/step - loss: 0.4968 - accuracy: 0.0000e+00 - val_loss: 0.4837 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 105s 559ms/step - loss: 0.4968 - accuracy: 0.0000e+00 - val_loss: 0.4837 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 105s 557ms/step - loss: 0.4968 - accuracy: 0.0000e+00 - val_loss: 0.4837 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 105s 557ms/step - loss: 0.4968 - accuracy: 0.0000e+00 - val_loss: 0.4837 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 105s 558ms/step - loss: 0.4968 - accuracy: 0.0000e+00 - val_loss: 0.4837 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 105s 557ms/step - loss: 0.4968 - accuracy: 0.0000e+00 - val_loss: 0.4837 - val_accuracy: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9443GOR9k2PY"
      }
    }
  ]
}